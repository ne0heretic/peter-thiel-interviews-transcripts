[Peter Thiel on 'Anti-Anti-Anti-Anti Classical Liberalism' | Oxford Union"](https://youtu.be/fQ4rc7npiXQ)

[00:00:02] foreign [Music]

[00:00:07] members honored guests good evening and welcome to the first event of

[00:00:11] Hillary term 2023 and the first event of the 200th anniversary

[00:00:14] year of the Oxford Union 200 years ago a group of students

[00:00:18] met in a small room in Christchurch determined to have discussion free from the

[00:00:22] restrictions of the university and two centuries later we proudly

[00:00:25] continue this tradition by providing our members across the globe with opportunities

[00:00:29] to question their most fundamentally held beliefs and by standing up for free speech

[00:00:33] and expression it brings me great pleasure to welcome Mr Peter Thiel to

[00:00:36] give the inaugural address of the Oxford Union's bicentenary Year Mr teal

[00:00:40] is an American Technology entrepreneur and investor he co-founded

[00:00:44] PayPal and palantir made the first outside investment in Facebook and

[00:00:48] has funded companies like LinkedIn and Yelp Mr teal

[00:00:51] also founded the teal Foundation which works to advance technological progress

[00:00:55] and long-term thinking via funding non-profit Research into

[00:00:59] artificial intelligence life extension and sea setting ladies

[00:01:03] and Gentlemen please join me in welcoming Mr Peter Thiel [Applause]

[00:01:22] well Charlie thank you so much for that terrific introduction and

[00:01:26] a lot of different things to to cover I'm always reminded of a

[00:01:30] question a colleague of mine like to to ask what is the

[00:01:33] antonym of diversity what

[00:01:37] word is the single antonym of diversity and University

[00:01:42] and uh and I think uh it is such a great honor and privilege

[00:01:46] here to uh to speak here at the Oxford Union where

[00:01:50] for 200 years uh people have been uh thinking about

[00:01:54] the crisis of the university the crisis of the West the crisis

[00:01:57] of Classical liberalism there's there are elements of this that are of

[00:02:01] course Timeless and eternal and then of course there are parts of it that

[00:02:04] are always you know there's always sort of a kaleidoscopic uh

[00:02:09] newness uh and uh effervescence

[00:02:12] to to it as well you know I I uh I

[00:02:16] framed my my talk as anti-anti anti-anti-classical liberalism

[00:02:20] so you have a double negative that's kind of a positive a quadruple negative is also kind of a

[00:02:24] positive and and uh if you uh and I'm going to try to sort of

[00:02:27] outline uh as I see the uh the argument

[00:02:31] as well as the best arguments against the university the

[00:02:35] Classical liberalism um you know sort of the free

[00:02:38] western world and uh and at the end of the four negatives

[00:02:42] I will still come down um on something that I think is is

[00:02:46] quite close to uh to uh the values that uh would have

[00:02:49] animated the Oxford Union uh already 200 years ago

[00:02:53] uh now I you know I I'll start with sort of a little bit of a historical

[00:02:57] anecdote you know I was I was a student at Stanford University in

[00:03:01] the late 80s early 90s we had a lot of these uh crazy

[00:03:04] culture wars uh you know Wars about the nature of the

[00:03:08] University one of the ones where I sort of first came in some ways

[00:03:11] to sort of political awareness was an intense debate at

[00:03:15] Stanford about the Western Canon uh a course called Western cultures

[00:03:19] that required fresh freshman course in some ways was a debate about the

[00:03:23] course but of course it was also debate about the whole Western Civilization it represented

[00:03:27] there was a famous uh um protest that uh Jesse

[00:03:30] Jackson LED at Stanford uh hey hey ho ho Western cultures got to go was

[00:03:34] it sort of referendum on the course and on and on our entire

[00:03:38] civilization and and I started one of these sort

[00:03:41] of independent conservative libertarian alternative newspapers

[00:03:45] we saw we should like investigated we needed to sort of describe

[00:03:49] the new curriculum we need to figure out ways to denounce the new curriculum and uh

[00:03:53] in the the 88-89 term one of the new classes called

[00:03:57] a sort of innovative new class was Europe and the Americas which was not

[00:04:01] really a non-western but more an anti-western uh sort of polemic

[00:04:04] and you had sort of all these different authors and I thought you know I should go to the bookstore and

[00:04:08] just read through the books and find people to illustrate

[00:04:12] uh the the sort of parochiality and tendentiousness of

[00:04:15] of this uh of this new curriculum and I I I came on one book

[00:04:19] that somehow was almost too good to be true it was sort of summarized

[00:04:24] um like in onion episode everything that was you know stereotype of everything

[00:04:27] was ridiculous about the new curriculum it was a a story of I rigobert to

[00:04:31] mention she was a Guatemalan native and she's sort of been victimized

[00:04:35] by every Vector of Oppression imaginable she was you know she was a she's

[00:04:39] a poor she was a peasant she was an Indian she was an

[00:04:42] orphan and and then you have sort of all and sort of she sort of

[00:04:46] achieved some sort of revolutionary communist Consciousness in the course of this uh of

[00:04:50] this uh polemic book you know she renounces marriage and motherhood she makes plans

[00:04:53] for the May Day Parade these are sort of the chapter titles of the book um you know I

[00:04:57] wrote it up and as so many of these debates in campus it's something I

[00:05:00] was on some little very narrow issue that somehow kicked off a

[00:05:04] broader discussion you know as a 19 year old Junior at Stanford managed

[00:05:08] to uh get get the get this reprint in the Wall Street Journal

[00:05:12] uh when uh you know when uh some of theconservatives wrote books

[00:05:15] about uh about uh the insanities of the universities in the late 80s

[00:05:19] early 90s uh uh one of the uh conservative people the Stanford

[00:05:23] chapter was entitled travels with rigoberta sort and so sort of it I

[00:05:27] I of succeeded in turning her into an icon for for this

[00:05:31] thing and then uh you know then sort of four years uh four years later

[00:05:35] uh fall of 1992 I'm not clerking for for a judge

[00:05:38] and driving to work in Atlanta Georgia and uh on the radio it's

[00:05:42] uh you know we just have an announcement we have someone who's just been selected

[00:05:46] for the Nobel Peace Prize someone nobody's ever heard of it's

[00:05:49] rigoberto menshu and uh and I sort of realized

[00:05:53] at that moment that uh yeah I thought I was engaged in some kind

[00:05:57] of cosmic battle between the forces of Good and Evil and actually I

[00:06:00] had just been a two-bit actor in some left-wing drama where

[00:06:04] I had completed her victimization and uh and

[00:06:08] then you know I I was the proximate cause of her getting her Nobel Peace

[00:06:11] Prize but but I think I was I was the butt for cause but for

[00:06:15] me she would not have would not have gotten it and uh and this

[00:06:19] is sort of the odd feature of so many of these uh these super intense

[00:06:23] debates where uh you sort of Wonder you know what is what

[00:06:26] is it that is really going on what is it that is uh that is perhaps

[00:06:30] uh really at stake that that we should be uh talking

[00:06:34] about in instead and um and so if I look

[00:06:37] back you know on the debates

[00:06:41] at Stanford the time and some extent these debates I

[00:06:45] think they've been fought for you know for decades or centuries

[00:06:50] um if we took not the tendentious left wing but let's say the sort of

[00:06:53] bureaucratic University perspective or

[00:06:57] the establishment perspective uh what they what

[00:07:01] they would have said in the 1980s would I think they still in many cases would say

[00:07:04] today what they would have said in the 19th centuries yeah you

[00:07:08] have you have all these you know flaky debates in the Humanities

[00:07:12] about reading Shakespeare and reading these books but you

[00:07:16] know we're doing something much more important the university is about progress

[00:07:19] progress of knowledge and it's especially true in the Science

[00:07:23] and Technology that's where progress is happening

[00:07:27] and um and we can have these these side debates about Shakespeare

[00:07:30] rigor bear to Menchu but we're working on string theory

[00:07:34] and Science and these sort of um the relief of

[00:07:37] man's estate the Roger Bacon Francis

[00:07:41] Sir Francis Bacon that whole that whole thing that's what the university is

[00:07:46] uh is really all about and I think this this would have been the

[00:07:49] the technocratic sort of Defense Stanford have given of itself in

[00:07:54] the 80s and 90s uh that uh that that yes the

[00:07:57] the progress is continuing it's continuing uh very

[00:08:01] rapidly and this is what's What's um what is sort of uh

[00:08:05] what is going on in our society and that's that's what's fundamentally good it's the

[00:08:09] Manhattan Project it is the Apollo space program it

[00:08:12] is um it is the progress of humanity and

[00:08:16] uh and as long as we're doing that you shouldn't you know you can complain about these

[00:08:19] side shows but it doesn't really matter and so I think

[00:08:23] one of the one of the debates that I came to uh one of the perspectives

[00:08:27] I came to start to wonder about though um in the

[00:08:30] late 90s 2000s was um you know yeah

[00:08:34] we have so many of these culture wars are about these issues that everybody can understand these

[00:08:39] books or you know Shakespeare versus rigor bear to mention or something like this but

[00:08:43] um perhaps things are um just as unhealthy in

[00:08:47] The Sciences in in all these other disciplines that are after all

[00:08:50] far more narrowly the domains of experts you

[00:08:54] know um you know you have a sense that if you substitute rigor bear dementia for Shakespeare

[00:08:58] something weird is going on if only 100 people in the world understand

[00:09:01] string theory and you have this sort of narrow group of Guardians guarding themselves

[00:09:05] shouldn't the a priori assumption be that string theory is actually more

[00:09:09] corrupt than the humanities or the Sciences are in many ways more corrupt in

[00:09:13] the humanities and uh and one of the one of the early people uh

[00:09:16] who uh who drew my attentions was a professor at Stanford Bob Laughlin who

[00:09:20] uh um got a Nobel Prize in physics in the late

[00:09:24] 1990s he sort of was a somewhat difficult uh

[00:09:27] person uh a friend of mine was getting his uh doing his PhD work with with

[00:09:31] Laughlin and uh but he had the Supreme delusion

[00:09:35] that now that he had a Nobel Prize in physics he had complete

[00:09:39] academic freedom and he would be allowed to investigate and talk about anything he

[00:09:43] wanted to and there are of course a lot of controversial topics

[00:09:46] in The Sciences we could imagine you could question climate change you could talk

[00:09:50] about you know intelligence and genetics you would talk about uh you

[00:09:54] could talk about um you'd question Darwinism I mean there's all sorts of things that

[00:09:57] are quite Taboo in The Sciences but he picked an area that was far

[00:10:01] worse far more dangerous than any of those uh and he

[00:10:05] was convinced that most of the scientists even at a place like

[00:10:08] Stanford University were engaged in borderline fraudulent

[00:10:12] research they were stealing money from the taxpayers um and uh

[00:10:16] and it needed to be investigated it needed to be stopped and

[00:10:20] uh you know I I don't even sort of probably don't even need to tell you too much about how that movie ended

[00:10:24] it sort of ended quite badly uh he got defunded

[00:10:27] his graduate students couldn't get phds anymore and uh

[00:10:31] and the kind of hermeneutic Suspicion I always have is that you know I wouldn't

[00:10:35] say it's automatically the case that if something is taboo that it must be perfectly

[00:10:39] 100 accurate but uh my suspicion is that

[00:10:42] if something is this taboo this forbidden you have to at least ask

[00:10:46] some some sorts of questions and and

[00:10:50] the uh you know the general thesis that I've been articulating and different for a

[00:10:54] for close to two decades is that

[00:10:58] umthere is something about science and technology that's not progressing

[00:11:01] as quickly the specialization means that it's very hard to evaluate

[00:11:05] uh you have all these different uh sub-specialists that uh propagandize

[00:11:09] about themselves the cancer researchers tell us they're going to occur cancer in five years

[00:11:12] and they've been telling us that for 50 years and the string theorists say they're the

[00:11:16] smartest people in the world they know everything about physics and we're about to have quantum

[00:11:20] computers and and on and on Down the Line and

[00:11:24] uh and yet um in in many ways we

[00:11:28] seem to have been kind of stuck uh you know the uh if you if

[00:11:31] you if I go back to when I was an undergraduate Stanford almost all

[00:11:35] the engineering fields that one could have gone into would have been mistakes it was a mistake

[00:11:38] to go into aeroaster engineering it was a mistake to go into nuclear engineering I think people already understood

[00:11:42] that by the 80s these these fields were stuck they were outlawed they weren't

[00:11:46] going to advance you weren't going to make any progress in mechanical engineering chemical

[00:11:50] engineering all these things were bad ideas the one that still held

[00:11:53] up pretty well in the in the late 80s early 90s another decade

[00:11:57] was electrical engineering semiconductors and then probably you

[00:12:01] know the one the one very silly field that actually did kind of work was

[00:12:04] computer science and I always think that the that when you have fields

[00:12:08] that include science that's always a tell that you have an inferiority complex

[00:12:12] because uh you don't need to call it physical science or chemical Sciences physics

[00:12:16] or chemistry uh but it's computer science like political science or climate

[00:12:19] science it's sort of a like a deep sense of inferiority and yet

[00:12:23] these people who were um who had like were had relatively uh

[00:12:27] bad math genes and went into this uh this sort of uh very

[00:12:30] very degenerate Fields compute called computer science this was the one thing that

[00:12:34] kind of worked the last 30 35 years and we had you

[00:12:38] know some sort of progress around this world of bits

[00:12:41] um computers internet mobile internet you know maybe

[00:12:45] I'll uh I really dislike that word uh and they're probably

[00:12:48] ways that even that progress has has somewhat um stalled

[00:12:52] out or become less utopian in the in the last decade but

[00:12:56] uh but for the last uh 40 or 50 years outside the

[00:13:00] world of bits it has been a story of General stagnation uh

[00:13:04] and then not just in the fields not just in terms of you

[00:13:08] know no big breakthroughs but of course also you know if we

[00:13:11] try to measure it economically we have this very odd situation in

[00:13:15] the UK or the U.S where for the first time in

[00:13:19] decades and centuries Beyond count the younger generation

[00:13:22] has lower economic expectations than their parents and

[00:13:26] uh this is this just very oddly doesn't fit with the

[00:13:29] sort of kurzweilian pan glossian accelerationism

[00:13:34] the singularities near and all you need to do is sit back and eat some

[00:13:37] popcorn and watch the movie The Future unfolds so so there's something about

[00:13:41] uh about the uh the the stagnation problem that

[00:13:45] uh that runs um one's quite deep seems to be quite

[00:13:49] quite multi-faceted I I sort of tend to date it back to something

[00:13:52] like the early 70s the oil shocks the inflation a

[00:13:56] time when you know money no longer grew on trees because we didn't have

[00:14:00] this incredible Tailwind of scientific and technological progress that

[00:14:03] was just advancing on its own so um so yeah to recap

[00:14:07] where we are on the argument the uh the rebuttal to the rebuttal The Classical liberalism

[00:14:11] the rebels of The Classical liberalism is just we

[00:14:15] don't need to do the humanities we don't need to ask questions about the university about

[00:14:19] the whole we can just we can just focus we can just tell people to

[00:14:23] um to organize disciplined and work on Sciences sort of like the way

[00:14:27] the New York Times wrote about the the Manhattan Project in 1945

[00:14:31] it's sort of paraphrasing it but sort of you know there are these sort of free market

[00:14:34] uh libertarian type people who think that uh

[00:14:38] you know uh who didn't believe that science should be run by the military but

[00:14:42] um you know they've hopefully they're gonna be quiet now because the military was able

[00:14:46] to when they organized all these scientists was able to invent this device

[00:14:49] a nuclear bomb in three and a half short years which maybe if you left the prima

[00:14:53] donna scientists through their own devices would have taken 50 years or something like that

[00:14:57] um but anyway New York Times doesn't write articles op-eds like that anymore

[00:15:01] and uh and so there was yeah but there was sort of a certain non-classically

[00:15:05] liberal organization regimentation that uh you know may

[00:15:08] accelerate may have accelerated things for a while but uh that now is

[00:15:12] completely exhausted and uh and so instead of getting into this debate about rigor

[00:15:16] bear dementia Shakespeare or string theory um the rebuttal to the

[00:15:20] rebuttal is they're not doing String Theory they're not doing science it is

[00:15:23] it is all stalled out beyond belief and uh

[00:15:27] and this is as I said this is sort of the the uh the

[00:15:30] main frame of this debate that I've been I've been giving for uh argument

[00:15:34] that I've been making for something like the last uh two decades

[00:15:38] now one of the questions I always get asked in this context is well

[00:15:42] why why did it stall out what what happened what went what

[00:15:45] went wrong and then my sort of sort of slightly politically correct

[00:15:49] answer was always well you know questions that start with why

[00:15:53] are always over determined they're hard to answer it's probably determined by a whole bunch

[00:15:56] of different things and you know you can say um there's too much regulation

[00:16:00] you know the FDA regulates biotech too much so it's

[00:16:03] hard to do things in biotech you know if you have um you know if you

[00:16:07] if you had as little regulation as you have for video games for new uh

[00:16:11] drugs maybe we'd have more drugs there's so there are ways you can sort of blame education

[00:16:14] or government funding um but the um but this the

[00:16:18] single answer that I've I've come to believe as to why

[00:16:22] why it is stalled out um and this is and I believe

[00:16:25] this has now actually become the the the argument

[00:16:31] um on the part of the universities on the part of our zombie Central left

[00:16:34] establishment is something like science

[00:16:38] and technology are just too dangerous and so what

[00:16:42] what um what looks like it's a bug that things

[00:16:45] are no longer progressing is actually a feature and we should be

[00:16:49] really really happy that it's not progressing because

[00:16:53] um Science and Technology are this giant trap that humanity is

[00:16:57] building for itself and this is this is sort of what gets articulated

[00:17:01] in all sorts of different versions existential

[00:17:05] risks you know there's all these ways that that uh that

[00:17:09] this uh this this um these things sort of bacterium probably and

[00:17:13] again you know these timelines overlap in different ways probably

[00:17:17] the the original version of this was already involved

[00:17:22] um nuclear power of nuclear weapons thermonuclear weapons the fear

[00:17:25] of fear of nuclear war didn't probably hit people right away in 1945

[00:17:30] but uh but by the time you get to um

[00:17:33] you know by the time you get to the late 60s early 70s you get someone

[00:17:37] like Charles Manson uh the crazed person on LSD goes

[00:17:41] around killing everybody in Los Angeles you know if you ask what did he see what

[00:17:44] did he see on his psychedelic drugs um well he figured out the world was

[00:17:48] coming to an end and therefore you could be like uh Russ kolnikov and

[00:17:51] Dostoyevsky and not everything was permitted in in this crazy world you

[00:17:55] could do anything you anything you could do to stop science to

[00:18:00] um to to slow it down because uh it was just accelerating

[00:18:03] in this in this catastrophic way and I think something like this

[00:18:07] is is true of so many of these different areas that if

[00:18:11] we really think about it they have sort of this this dangerous there

[00:18:15] is some sort of dangerous dual use component that you know that

[00:18:19] the space program was was you know had the Dual use thing of just uh delivering

[00:18:23] icbms more quickly halfway around the planet or

[00:18:27] um or or sort of the rhetorical question I'd like to ask in in an

[00:18:31] American context is you know why can't we have ticker tape parades for

[00:18:34] individuals why can't we celebrate individuals anymore and sort of a ticker tape

[00:18:38] parade in New York and um and why can't let's pick

[00:18:41] left-wing individuals individuals who fit the left-wing narrative why can't we have a

[00:18:45] ticker tape parade for the you know one or two the

[00:18:48] key scientists who developed the MRNA vaccine we're told this is this

[00:18:52] fantastic scientific technological breakthrough why can't

[00:18:56] we celebrate this and um and my sort of cultural

[00:19:00] thesis is that uh it is immediately adjacent

[00:19:04] in people's minds to this great existential fear because

[00:19:07] the MRNA vaccines somehow remind us of

[00:19:11] this thing going on in the Wuhan lab that was called I had this orwellian

[00:19:15] term gain of function research which sounds sort of like a bioweapons

[00:19:19] program in Disguise and if you can and so yes if you can um

[00:19:22] if you can manipulate DNA you can come up with these fantastic

[00:19:26] mRNA vaccines does that also mean that

[00:19:30] it's immediately adjacent to these uh to these sort of terrific

[00:19:33] terrific destructive weapons probably you

[00:19:37] um know probably the uh the area the existential risk

[00:19:41] area that's uh you know that's the most um

[00:19:44] that's the most uh um inside attack if

[00:19:48] you say when again Tech is always a strange word where it used

[00:19:52] to mean all these areas and it just came to me in I.T computers but

[00:19:56] within computers probably the the futuristic narrative is

[00:19:59] always around AI artificial intelligence artificial general intelligence

[00:20:03] all these things and 20 years ago when

[00:20:08] um I started getting involved in a lot of these things the narrative was still it

[00:20:11] was still generally a positive utopian it

[00:20:15] was it was people thought you know it's kind of a dangerous technology you know if you

[00:20:18] build uh this uh this this computer that's as smart or smarter than

[00:20:22] any human being in the world it's kind of dangerous but we're gonna have to work really hard

[00:20:26] to make sure it's friendly that it's aligned with humans and

[00:20:30] uh and and it was still sort of Circa 2003

[00:20:34] whatever misgivings people might have had about biotech

[00:20:38] or you know or um Rockets

[00:20:42] or nuclear power

[00:20:46] they did not yet have about Ai and the AI narrative was still

[00:20:49] a generally positive utopian one and uh and

[00:20:53] there's sort of a strange way where this has completely flipped over

[00:20:57] the last um over the last decade or so I was I was involved a thing

[00:21:01] called The Singularity Institute which pushed

[00:21:04] a sort of accelerationist utopian technology we we're

[00:21:08] progressing we need to progress faster we need to of course be a little bit careful and

[00:21:12] I sort of remember thinking to myself by 2015 I reconnected so many

[00:21:15] people and it didn't feel like they were really pushing

[00:21:19] the the AI thing as fast as before and it sort of devolved

[00:21:23] into you know some kind of Escapist burning man camp

[00:21:28] um and you sort of got the sense that uh it had shifted from

[00:21:31] transhumanism to Luddite something Luddite where no

[00:21:35] actually we want to slow this down it feels kind of dangerous it's

[00:21:39] kind of it's kind of a bad it's kind of a bad

[00:21:42] thing on on net and this this finally this the suspicion

[00:21:46] I think was finally confirmed you can look this up on the Internet uh I'm gonna

[00:21:50] read this it's from April 2022 less than a year ago

[00:21:53] Eliezer udkowski who's one of the sort of thought leaders of the

[00:21:57] sort of futurist um AI [Music] um

[00:22:01] um and the it's a a post from the machine intelligence

[00:22:05] Research Institute and it's announcing a new death

[00:22:10] With Dignity strategy and so uh and

[00:22:13] so uh the the short version of this it's obvious at

[00:22:17] this point that Humanity isn't going to solve the alignment problem

[00:22:21] how to get the AI aligned with humans or even try very hard

[00:22:25] or even go out with much of a fight since Revival is unattainable

[00:22:29] we should shift the focus our efforts to helping Humanity die

[00:22:33] with slightly more dignity uh again I

[00:22:37] want to underscore you don't deserve to die with a lot of dignity because you're not

[00:22:40] going to try very hard or even go out with much of a fight um but

[00:22:44] uh but it is it is it is an extraordinary it's

[00:22:48] an extraordinary way that the uh the context is shifted

[00:22:52] um you know I I'm probably and of course you know we can come up with

[00:22:55] other ones probably the uh the sort of the most uh mass-market

[00:22:59] version of the sort of catastrophic existential risk is the

[00:23:03] uh the climate change um the climate change one

[00:23:06] where um you know I I can just uh you know reference uh

[00:23:10] probably reference Greta and the sort of autistic Children's Crusade

[00:23:14] and um and uh and

[00:23:18] is again this is uh this is how how the world is is going to end

[00:23:21] this sort of runaway technology and of course you know um

[00:23:25] all these things I don't want to minimize don't want to say they're

[00:23:28] they're not real but it's striking how none of the solutions involve

[00:23:32] more technology so the solution to climate change is not you

[00:23:36] know Fusion reactors the solution to you know nuclear

[00:23:41] um nuclear um weapons is not better anti-ballistic

[00:23:44] missile systems this you know the solution um the solution

[00:23:48] to AI you know uh the solution to biotech

[00:23:52] is not accelerating the research even faster it is just somehow

[00:23:55] somehow stopping it all together and uh and

[00:23:59] and you know one is tempted to say that if anything most

[00:24:03] of these people are are insufficiently apocalyptic you know you

[00:24:06] want you want to you want to get Greta and try to actually want to talk to her but but

[00:24:10] you want to get someone like Rada and tell her you know wow you are

[00:24:14] a very complacent non apocalyptic person

[00:24:17] because you're only worried about this climate change thing and we also have this nuclear weapons thing

[00:24:21] that has made people go crazy for 70 years already and we have we have

[00:24:24] the AGI that's going to kill everybody at the singularity and we have you

[00:24:28] know and we have uh we have the Wuhan lab which you don't seem to be worried about at

[00:24:32] all and the bio weapons and uh we have we have this happening

[00:24:36] on on so many so many different dimensions and this is roughly

[00:24:39] where I think the Zeitgeist is in in 2020

[00:24:43] to 2023 um the sort of central left zombie

[00:24:47] Zeitgeist as articulated by by the universities it is

[00:24:51] it is we're not doing science we're proud that we're not doing science we're proud that

[00:24:54] we're stopping science we're proud that it um it

[00:24:58] is um it has been slowed down as much as possible

[00:25:02] um and you know maybe maybe a little bit unfair to pick

[00:25:06] pick on him but I I um I I'm reference an Oxford

[00:25:10] Professor Nick Bostrom who um is is at least smart

[00:25:13] enough to know that all these things add up and that these

[00:25:17] are all problems and umthat's not just sort of one

[00:25:20] or the other and um and I think of him as sort of a mouthpiece

[00:25:24] of the Zeitgeist um and he sort of wrote this paper back

[00:25:28] in 2019 so this is pre-covered before everyone went totally insane with

[00:25:32] covet so it doesn't have that excuse but cult the vulnerable World hypothesis

[00:25:36] sort of and it outlines all these different existential risks climate change nuclear

[00:25:40] weapons um runaway nanotechnology the robots

[00:25:43] killing everybody the AI killing everybody runaway bio weapons

[00:25:47] etc etc and and there are four things that

[00:25:50] must be done to stabilize the world um uh again it's written

[00:25:54] in the most boring language possible it's just channeling Zeitgeist I'm

[00:25:59] out number one restrict technological development

[00:26:02] number two ensure that there does not exist a large population of

[00:26:06] actors representing a wide and recognizably human distribution

[00:26:10] of motives I believe that's diversity but um

[00:26:15] um but then he goes on to say that one and two sort of don't quite happen on

[00:26:19] their own and therefore you need number three establish

[00:26:23] a extremely effective preventive policing

[00:26:27] and number four you need to establish effective Global

[00:26:30] governance and and I he does not quite

[00:26:34] use the word totalitarian but it is basically um you

[00:26:38] know the um the solution the solution to the sort of

[00:26:42] um existential uh risks in our vulnerable world is

[00:26:45] to have a is to have a one world totalitarian state and

[00:26:50] um and this gets me to my uh my concluding

[00:26:54] point the um the anti-anti anti-anti

[00:26:58] classical liberal argument is that uh if we are

[00:27:01] going to enumerate all these existential risks and we have

[00:27:05] to talk about them we have to discuss them we have to think about them we should not hide under

[00:27:08] the Rock and pretend these things are not real but we have to make the

[00:27:12] list complete and I would I would include as

[00:27:16] a very very serious existential risk

[00:27:19] um you know the risk if you end up with a one world totalitarian

[00:27:24] state that also counts as an existential risk and it seems to

[00:27:27] me that we shouldn't um we shouldn't uh we

[00:27:31] shouldn't short be too short-sighted about that one we uh

[00:27:35] we should we should always fight that that's something that always needs to

[00:27:39] be stopped you know um you know I I should

[00:27:42] I should uh not need to remind you that in the uh you

[00:27:46] know in the sort of quasi-methological New Testament account the the

[00:27:49] slogan of the Antichrist is peace and safety

[00:27:53] and um and uh and that there is there is you

[00:27:57] know we're we're told that umthere's nothing worse than Armageddon

[00:28:01] but perhaps there is perhaps we should fear the Antichrist perhaps

[00:28:04] we should fear the One World totalitarian state uh more

[00:28:08] than Armageddon and uh perhaps we should uh we

[00:28:12] should stick with uh some of the tried and true

[00:28:15] um ideas of classicalism this this organization and this institution

[00:28:19] has been supporting for 200 years and keep going for another another 200.

[00:28:23] thank you very much [Applause]

[00:28:34] um before I hand over to questions from our audience I'll talk about

[00:28:37] a few questions for you about the content of your speech you'll start

[00:28:41] where you've ended your speech on the threat of authoritarian government

[00:28:45] uh as a as a challenge or solution to the

[00:28:49] problems of Technology um but you also enumerated

[00:28:52] the problems of specialized technological progress which is something that

[00:28:56] has impacted public ability to engage in technology for decades like

[00:29:00] 40 years ago most people would have been able to understand why

[00:29:03] their car was broken and potentially fix it themselves whereas now if a car breaks

[00:29:07] it's most likely due to a software or electrical problem that no one will be able to deal with

[00:29:11] is technological development rather than handing over power

[00:29:15] to an authoritarian State Lord instead ever seeding

[00:29:18] ground to authoritarian technological companies

[00:29:23] well there are all sorts of um dimensions of

[00:29:26] this um I I tend to I still uh tend to think the

[00:29:30] problem of the state is much bigger than the problem of big tech companies

[00:29:34] or if there is a problem with big tech companies it is just that they are

[00:29:37] very efficient vehicles for state power and that

[00:29:41] they will you know very um very effectively uh be used uh

[00:29:45] be used by the state um and uh yes there's there's a

[00:29:48] problem with um you know there's probably a problem with you

[00:29:52] know some kind of specialization there's a problem with um you

[00:29:56] know uh with the problems with concentration

[00:30:00] um but I I I keep coming back to I think the bigger problem is

[00:30:04] one of just stagnation itself and

[00:30:07] uh and you know the um you know certainly stagnation

[00:30:11] specialization is this very deep problem of late modernity it's like

[00:30:15] the pin Factory in Adam Smith where you're 100 different people working on different parts

[00:30:18] of the pen and this doesn't sound um it doesn't sound very

[00:30:22] charismatic it might be efficient but but

[00:30:26] sort of if you tell people you're a small Cog in a big machine and the future

[00:30:29] is going to become an Ever smaller Cog in an Ever bigger machine that's uh

[00:30:33] that's profoundly uncharismatic and there are problems with that but

[00:30:37] uh but the question I just keep coming back to is is that even true and

[00:30:41] you know we're told the story of specialization we're told that all these

[00:30:45] narrow experts are making breathtaking progress and

[00:30:49] uh I I worry that uh the problem of hyper specialization

[00:30:52] is just there's no accountability and it all just has become a

[00:30:56] crazed rocket leading on from this question about the

[00:31:00] influence and Authority that can be held by companies a result of this very

[00:31:04] interested research in fund lots of to do with article artificial intelligence

[00:31:07] coding and algorithms all algorithms aren't naturally written

[00:31:11] by individuals who have biases and beliefs of their own

[00:31:15] disproportionately they are white men from the Northern Hemisphere as

[00:31:19] these algorithms continue to play more and more of an influence in our

[00:31:22] lives looking forward 50 or 100 years do you think that

[00:31:26] these biases and beliefs will entrench themselves in the very

[00:31:30] fabric of our society well

[00:31:33] it's uh man the the AI topic is obviously a super a

[00:31:37] super a super broad one the um what I what

[00:31:41] I would um what I would say is I I don't know if we

[00:31:45] actually need to get to the a super futuristic

[00:31:49] versions of AI for it to be um for it to be problematic

[00:31:52] where it's um this super intelligent computer or or

[00:31:56] or something like that uh the the the the version of

[00:32:00] it that I think is the most real and the most problematic is something like

[00:32:03] what you see in in communist China where it's it's

[00:32:07] um it's fairly low-tech but it is just this pervasive

[00:32:11] surveillance um you know it's we can say it's the computers

[00:32:14] that are doing it but it's always some people behind the computers there's always

[00:32:18] a a political question of sorts and uh and

[00:32:22] the you know the the rhetorical frame that I've come up with is you

[00:32:25] know you could um we'd have we have all sorts of debates whether AI

[00:32:29] is conscious or whether it's intelligent or super intelligent

[00:32:34] um but uh but if we avoid the political question of how it gets

[00:32:37] used in in places like China um you know maybe it's merely

[00:32:41] evil and maybe something can be merely evil it's not conscious

[00:32:45] it's not even intelligent it's merely evil and that's but

[00:32:48] I I would say yeah the the problem is is is China

[00:32:52] far more than in the West so the evilness is

[00:32:55] the individuals behind it or the technology itself it's

[00:32:59] it's the technology tilts it tilts towards surveillance

[00:33:03] um and then it's always uh yeah there's always some totalitarian

[00:33:08] uh in a set of um a Class party

[00:33:11] that can that can stand behind it um you know I don't think there's it's

[00:33:15] I don't think it's absolutely intrinsic to the technology but the the line I've

[00:33:19] used is that you know if people say that uh crypto is libertarian

[00:33:23] which I might not even fully believe anymore but if you were to say that crypto is

[00:33:26] libertarian then why can't we say that AI is is communist

[00:33:30] it's not completely inherent in it but it's a it's a certain tendency

[00:33:34] in it and uh and while I am I am pro-acceleration I'm

[00:33:37] Pro-Tech I'm even Pro AI um it is probably the one technology

[00:33:41] that I have the most misgivings about I'll have a few questions about

[00:33:45] cryptocurrency and currency in general later but an

[00:33:49] argument perhaps in favor of this rejection of Technology

[00:33:52] the Luddite case you presented is that

[00:33:56] repeated studies across the United Kingdom uh America Canada Western

[00:34:00] countries have shown that levels of individual satisfaction have

[00:34:04] not really increased and in some cases decreased since the 1960s

[00:34:08] despite huge increases in um ability

[00:34:12] or satisfaction of living supposedly technological advances

[00:34:15] why do you think this is and if technological advances

[00:34:19] do not improve individual satisfaction why they're worth pursuing well

[00:34:22] you at least in your question at least had the adverbs supposedly and

[00:34:26] I always I always think adverbs are very important because they're always a tell like in

[00:34:30] poker that the exact opposite is going on so yes we've been told supposedly if

[00:34:33] there is a lot of progress I I would want to question it I I believe

[00:34:37] um I believe the econ numbers more than the self-serving

[00:34:41] stories of the of the um university presidents

[00:34:45] and the bureaucrats and the the scientists and even the Silicon

[00:34:49] Valley Silicon Valley tech company so yes there's been a narrow cone

[00:34:52] of progress around the world of bits and the Internet it's not

[00:34:56] been enough to um to meaningfully increase the GDP

[00:35:00] per capita to meaningfully take our civilization the next level and

[00:35:03] that's that's that's why we submit things things feel that stuck

[00:35:07] now I I I'm not a lot I don't think we should embrace

[00:35:11] the stuckness I don't think we should embrace the stagnation I think the stagnation itself is

[00:35:15] you know ultimately unstable that you know we ultimately you know

[00:35:18] if we have a zero-sum society that will ultimately push us towards

[00:35:23] um you know the kind of lockdowns that we've seen the last two three years and

[00:35:27] then that I would argue in some ways we've had with respect to science and technology

[00:35:31] for uh for 40 or 50 years and that it's it's it's deeply unhealthy

[00:35:34] at the end of the day you know the luddites look uh they even if they were right

[00:35:38] about a lot of things they ultimately are wrong and you're ultimately you

[00:35:42] are you're going to lose if nothing else than in the military context

[00:35:46] you know it's as even even if the light's are right about everything

[00:35:49] you will you will always you know um you will you will lose

[00:35:53] to China on hypersonic weapons or space weapons or weapons

[00:35:56] in CIS lunar space or robots armed with AI and

[00:36:00] so uh so that probably there's something about the Luddite

[00:36:04] answer that's uh that's uh uh sort

[00:36:08] of self-destructive and uh and parochial at the same time

[00:36:12] giving your comments about the Manhattan Project and your Investments

[00:36:16] and engagement with palantir to what extent do you think that technological

[00:36:20] development is necessarily driven by war or a security dilemma

[00:36:24] well it's been a it's been a it's been a uh it's been a big

[00:36:28] big big part of it it's it's it's obviously it's obviously

[00:36:32] also been a big part of what what went wrong with it you know if if uh

[00:36:35] you know if we had enough nuclear weapons to destroy that world

[00:36:39] 20 times over you know I'm not saying what Charles Manson did

[00:36:42] where he just went insane started killing people was you know uh

[00:36:46] the the only reasonable thing to do but uh

[00:36:49] but there was there was a way that there was there was a way that it uh

[00:36:53] it drove a lot of progress and then it also deranged a lot of

[00:36:57] things and uh and we have to yeah I think we have to find

[00:37:00] some way to get back to the future where it's

[00:37:04] you know not dystopian not Luddite um you

[00:37:08] know not not accelerating simply towards Armageddon but also

[00:37:12] certainly not just the totalitarian lockdown is

[00:37:16] this partly why the stagnation you talked about scares you because you feel

[00:37:20] like stagnation and technological advancement in universities in the

[00:37:23] west will directly lead to the downfall of American and

[00:37:27] Western Supremacy um I I think I think I think it's

[00:37:31] bad for the west but I think I think even if there was no immediate external thing I

[00:37:34] think I think it will I think it will derange our societies you know if you

[00:37:38] have if you have no growth um uh

[00:37:42] then um then um then everything becomes a zero-sum rocket

[00:37:46] uh where you know there has to be a loser for every winner and

[00:37:49] uh and I'm not sure that necessarily gets you to socialist redistribution but

[00:37:53] it probably gets you to um to um something very

[00:37:57] different from the kind of society we've had the last few years so we've had this

[00:38:00] we've had this General stagnation and somehow you know we've

[00:38:04] we've been kept going by some kind of inertia but uh if

[00:38:08] if if it just stops uh yeah I think you end up with something much worse

[00:38:11] so I I don't trust that it's a stable outcome do you think this stagnation

[00:38:15] exists to the same extent in China and India and other growing

[00:38:19] parts of the world um there's uh

[00:38:23] I always think there's a difference between the developing and the developed worlds where the developing

[00:38:26] countries at least have or had some story of of

[00:38:30] um of convergence with with the developing world uh there's

[00:38:34] some program where they can copy things and uh and can catch

[00:38:38] up um um but I think even

[00:38:42] if they succeeded at doing that um which is probably the best case

[00:38:45] scenario I think they they will just run at the same problems we have so

[00:38:49] you know certainly um the way I I score I

[00:38:53] would still much rather consider

[00:38:57] myself fortunate to be in the Western World in the United States and

[00:39:01] uh we have this very deep problem of stagnation um I

[00:39:05] don't particularly want to move to China um you know the best case the

[00:39:09] absolute almost utopian best case for China is that they just

[00:39:12] copy the US and they end up where we are and uh and and

[00:39:16] I I tend to think my my mid case scenarios for them are much worse than that

[00:39:20] are there any areas that you think Buck the trend at any technological

[00:39:24] Fields That You Don't See stagnation and that you see hope for that you're interested

[00:39:27] in well look I I I think there is there is a lot that

[00:39:31] can be done on a you know in some ways I was giving a big picture

[00:39:35] of History talk and then what's always somewhat intention is

[00:39:39] I always believe in human Freedom

[00:39:42] um human agency I I believe that a lot more can be done

[00:39:46] you know I I invest in Technologies they're across many many

[00:39:50] different fields and uh and so I have the strong

[00:39:53] conviction that these are not it's not a law of nature that

[00:39:57] we've uh slowed down and uh it's not that the

[00:40:01] cupboard has run out or the cupboard is bare you know the the argument

[00:40:04] I articulated was was at its core cultural argument it was the people are

[00:40:09] too scared they've gotten too scared of Technology we could be doing a

[00:40:12] lot more people are scared I'm not I'm not I'm trying

[00:40:16] to steal man them I'm trying to say I understand why they're scared but

[00:40:20] um it is it is it is not a law of nature it's just a cultural artifact of

[00:40:24] where we are returning to the very start of your speech he said

[00:40:27] that he spoke about diversity in University being antonymical

[00:40:31] um do you think this is necessarily the case uh

[00:40:35] or not practical rather than etymological level and do you think that it's a

[00:40:38] result of society pursuing the wrong sorts of diversity and

[00:40:42] if so why so many uh polemical things uh

[00:40:46] one one could one could say about it uh probably

[00:40:51] um you know I I always like to say that you know you

[00:40:55] don't you know diversity is not merely um hiring

[00:40:58] the extras from the space Cantina scene in Star Wars you want you

[00:41:02] know you don't want just a group of people who look different and think alike

[00:41:06] um and then and then if you had you know if you had you know a

[00:41:10] genuine diversity of thought of ideas of viewpoints

[00:41:14] um I don't think that's inimical to I don't know a classic idea

[00:41:18] of a university as some sort of integrated holistic search for truth

[00:41:22] and uh and my intuition is that somehow you

[00:41:25] know if these things worked as they did in some bygone golden age or might

[00:41:29] in some future Golden Age it would somehow be involve

[00:41:33] genuine diversity on the level of the individuals and the

[00:41:36] professors and the researchers and um and

[00:41:40] uh and and some genuine uh Unity towards towards

[00:41:44] the truth and uh and the thing to underscore is that we probably have

[00:41:48] neither you know we neither have true true diversity nor

[00:41:52] true University and the sort of you know the the sort

[00:41:55] of Multicultural multiversity it's a it's

[00:41:59] a strange superposition of um you know hyper relativistic

[00:42:03] hyper nihilistic hyper totalitarian and you

[00:42:07] you will point out that those three things are all logically contradictory

[00:42:10] and uh and I can probably come up with some psychological analysis of why

[00:42:14] they go together but that's again very complicated given

[00:42:17] that when Europe University a couple of decades ago you wrote about the problems

[00:42:21] of political correctness and now you talk about decline

[00:42:25] in the academy and universities do you think there is a

[00:42:29] point where they seem to accelerate or do you think it's all relative

[00:42:33] to the world around it well it

[00:42:36] um you know they're not these plates are not completely isolated from from

[00:42:40] the broader Society but uh the umthe the piece

[00:42:44] that I did not connect when I when I was involved in these

[00:42:47] debates 30 years ago was I I thought of these debates as

[00:42:51] um sort of narrow ideological debates about the curriculum or about

[00:42:56] um you know even broader historical debates about Western Civilization

[00:42:59] or things like that and um and I I

[00:43:03] now think of them as as some of very very deeply connected to

[00:43:07] uh this question of um economic scientific and

[00:43:10] technological progress and in a society where

[00:43:14] um you know there is a lot of progress happening where things are getting better uh

[00:43:18] you can figure out some kind of a way that uh you have win-win

[00:43:22] Solutions things don't need to be this malthusian this

[00:43:25] uh this adversarial if you have you know 10

[00:43:29] postgraduate students in a chemistry lab or there's only a

[00:43:33] job for one of them and you have people having fights over beakers

[00:43:36] and Bunsen burners or whatever they have to do in a malthusian world then

[00:43:41] obviously if somebody says one Politically Incorrect

[00:43:45] thing and they get thrown off that overcrowded bus that's a relief to the other nine

[00:43:49] people so uh so yeah I I I I've

[00:43:52] come to think that at least large elements of it are linked to the sort

[00:43:56] of um stagnation malthusian economics things

[00:44:00] like that which uh which have a tendency to bring out the very worst in people last

[00:44:04] question before we move on from the academy do you think free speech is under

[00:44:07] threat a University's more than ever before or do you think that the

[00:44:11] threat is not there or is abating yeah it's

[00:44:15] you know I I think it's under I think it's under I will not

[00:44:19] tell you anything that yeah you haven't heard many times before that I I think it's under

[00:44:23] under a great deal of threat under a great deal of pressure

[00:44:26] uh I I always do

[00:44:30] Wonder though what what is it behind it so even if we you know even if

[00:44:34] you had perfect Free Speech even if the even if uh the channels

[00:44:38] were all open uh the pipes were not on not clogged

[00:44:41] what would actually be flowing through it and uh and I worry

[00:44:45] that the that the um these very uh ridiculous

[00:44:49] restrictions on free speech that we have are um are

[00:44:53] you know they're bad we shouldn't have them but they're also distracting us

[00:44:56] from uh the fact that people actually don't have very much to say

[00:45:03] um I hope not speaking for us there Peter um now the promised

[00:45:07] question on currency um do

[00:45:11] you believe that PayPal and similar operations have as you

[00:45:14] first claimed given Everyday People control of their currencies or

[00:45:18] is this an unachieved aspiration and might cryptocurrencies be

[00:45:22] the solution to that well I was uh I was

[00:45:26] I was super into Financial cryptography back in 1998 when

[00:45:29] I when I started PayPal and and there's

[00:45:33] certainly um there was this sort of um

[00:45:37] a classical liberal hope maybe some would say a fantasy

[00:45:41] that the computer age would decentralize things it would sort of have these

[00:45:45] decentralizing things that would give more power to

[00:45:48] small businesses to individuals to um to all these all these

[00:45:52] different groups of people and um and then there you know

[00:45:56] there's obviously a way that uh this these sort of cypher-punk

[00:46:00] crypto Anarchist a narco libertarian hopes of the late 1990s

[00:46:04] in many ways um it seems like the pendulum swung

[00:46:08] the other way and that uh there was something about computer technology

[00:46:12] that was centralizing in the form of big big companies

[00:46:15] big Tech big big governments um I I

[00:46:19] don't think it's absolute intrinsic to computer technology

[00:46:23] itself it's always possible for it uh for it to swing uh

[00:46:27] swing back you know big is an ambiguous word it can mean strong

[00:46:31] or it can mean fat and um and maybe

[00:46:34] um uh and and the and the cryptocurrencies present the

[00:46:38] hope that that things could uh could uh could go back

[00:46:42] the other way in in various forms but that's but yes we're

[00:46:45] we're if I if I had a bet on it I would say we are we're at at

[00:46:49] an extreme of um centralization of tech and

[00:46:53] uh and I would have some hope not sure how ground it is

[00:46:56] that that the pendulum could still swing swing back the other way before

[00:47:00] we open up the questions from the audience moving on to politics

[00:47:04] um first question why did you back president

[00:47:08] Trump in 2016 and do you regret it now

[00:47:12] you should ask me you should ask me this question in 10 years or so

[00:47:16] um but I I think the um you know I

[00:47:19] think I think this I I backed Trump for the same reason

[00:47:23] that if I was in the UK I would have been a pro-brexit person and

[00:47:26] and it was just this very deep conviction that

[00:47:30] uh that uh things were very off track you know our

[00:47:34] societies um they are too locked down too stagnant

[00:47:38] we need to change um you know there are there

[00:47:41] are critiques I could give of myself where I I I you

[00:47:45] know it was some kind of scream for help and uh

[00:47:48] and then um did that actually um you

[00:47:52] know help bring about the kind of debate I wanted to see about stagnation how

[00:47:56] to move Beyond stagnation um you know I think the jury's still very

[00:47:59] out on that in the U.S just as uh you know the brexit debate

[00:48:03] which in the UK you can think of as a debate about uh what's the

[00:48:07] identity of the UK and um The Hope was

[00:48:10] that brexit would would um you know sharpen would

[00:48:14] um that debate would help um uh form

[00:48:18] a better identity for Britain in the 21st century and

[00:48:22] uh and certainly for uh the first seven or eight years

[00:48:26] um there's a there's a there's a worry that both Trump and brexit actually

[00:48:30] uh delayed that much needed discussion more than they

[00:48:33] accelerated it why do you think that President Trump

[00:48:37] and I suppose brexit and the candidates you've backed in elections

[00:48:41] since Trump have failed to bring about that disruption to

[00:48:44] the stagnation well it's it's uh it's very hard to

[00:48:48] you know it's very hard to change look there's

[00:48:52] there's a way that politics there's a way that uh things like the Oxford

[00:48:56] Union are super important there's there's one layer where

[00:48:59] you talk about it and it's probably the the most singularly

[00:49:03] inappropriate thing I could say here is that you know it's not all

[00:49:06] about talk you know um it is sort of the um you know

[00:49:10] it's in in you know in the classical World sophistry is

[00:49:14] the belief in the omnipotence of speech and uh it's sort of

[00:49:18] like that's that's supposed to be Monopoly of the biblical God and somehow

[00:49:21] we you know we always want to have somehow speech combined with

[00:49:25] action we don't want to think that uh um just

[00:49:29] um saying the magic words is enough to trigger things and so

[00:49:32] and so to the extent people had that that conception

[00:49:36] about uh brexit or Trump or you know about Obama giving

[00:49:40] a speech in Cairo that these were these were forms of uh forms of

[00:49:43] sophistry forms of belief in the omnipotence of speech and uh and

[00:49:47] in a very similar way you know the tech stagnation problem that

[00:49:51] I touched on you know I I can tell myself that

[00:49:55] uh giving a talk at the Oxford Union is is a very small step

[00:49:58] towards it if I said that that was the Panacea wow that would

[00:50:02] be that would be insanely self-delusional

[00:50:05] um might be better for our reputation though um but yeah so

[00:50:10] talking about political donations in general you're one of the largest political

[00:50:13] donors in America and every election

[00:50:17] cycle literally billions of dollars are spent on

[00:50:21] the presidential campaigns or Congressional campaigns of

[00:50:25] both major parties billions of laws that could be used

[00:50:28] to fund Innovation break the stagnation or social

[00:50:32] projects or in any number of ways as a large political donor

[00:50:36] do you think that a culture of political donation is healthy uh

[00:50:39] the UK in comparison has very strict caps in the amount that political parties can spend

[00:50:43] campaigning both locally and nationally should the US adopt

[00:50:47] similar laws and if not why not well I

[00:50:50] I don't think it's um I don't think it's healthy for either of

[00:50:54] our societies to be as um as enmeshed in politics as

[00:50:57] they are um I think um I you know

[00:51:01] I always have a very schizophrenic view on it where I I think it's uh toxic

[00:51:05] and unhealthy and at the same time it's all

[00:51:08] important because it permeates everything you know so many of these problems

[00:51:12] won't have at least some political Dimension to to their solution

[00:51:15] I know challenging the premise of your question I would say it's it's shocking

[00:51:19] how little people spend on politics in the United States because uh

[00:51:24] um you know it just permeates everything and you know it

[00:51:27] is it is so all important even if it even it's not the not the only only

[00:51:31] Vector for solving it and so I think yeah there's

[00:51:35] um and the probably there probably is something about the UK version

[00:51:39] of it where it means that uh um if

[00:51:42] you if you can't do it these things just get displaced and in different

[00:51:46] in different forms and so if uh if individuals can't spend the money

[00:51:49] you know it means that you have even more power somehow uh resides

[00:51:53] an unelected bureaucracies and and you know and we have

[00:51:57] some again I don't want to exaggerate the difference between UK and us but but it's

[00:52:00] uh yeah the problem is is we are we're in a world

[00:52:04] where it's just uh it's just way too much politics I would I'd

[00:52:08] prefer to do away with it all together that's too utopian

[00:52:12] political political atheism that's that's an aspiration but

[00:52:16] does the world with large levels of political um donation

[00:52:20] not just privileged individuals such as yourself who can uh

[00:52:23] invest in political projects that you care about um whilst

[00:52:27] not allowing that level of political engagement that you said you should expect everyone to have given

[00:52:31] the importance of politics in everyday life oh but you could say you could say that about

[00:52:34] uh you could say that about investing in science you could say that about free

[00:52:38] speech about media platforms um you could say that about all all

[00:52:43] um all kinds of things so then then that just becomes a you know that that just

[00:52:46] becomes a question about uh about inequality inequality

[00:52:50] generally and and um you know

[00:52:54] um and and and then I I don't I don't think inequality is our biggest

[00:52:57] problem I think our biggest problem is stagnation but science and technology

[00:53:01] and social media companies don't claim to have an equal buy-in in the same way that democracy

[00:53:05] and politics do yeah but in in democracy and politics you

[00:53:08] have to you have to still somehow convince people it ends up being

[00:53:12] you know it ends up being you know a fairly competitive

[00:53:16] Dynamic on where there's a lot of funding on both sides it's

[00:53:19] it's kind of an arm's race so I I'm certainly

[00:53:23] my from my involvement I you know there's there's I would I

[00:53:27] would say it's always surprising how um how hard it is to impact things it's

[00:53:30] not like you can just spend money and people change their minds the translation

[00:53:34] function is is quite weak you know I'd I would I would like you

[00:53:38] it if um if um know if you could

[00:53:42] translate things more if you know if again just not just in politics

[00:53:45] but let's you know if I could if I could just spend some of my money and get cures

[00:53:49] for cancer or could you know overcome these things and

[00:53:53] uh unfortunately it's it's mainly not a financial problem it's you know

[00:53:56] it's a regulatory problem it's a social problem it's it's these other

[00:54:00] kinds of things but yeah the translation function is shockingly weak

[00:54:04] so the money doesn't solve the problems that you're identifying have you ever you try

[00:54:08] to use it but it is it is a shock the translation function is shockingly

[00:54:11] weak have you ever as a solution to that considered getting

[00:54:15] involved directly in politics yourself and running for election I'd go I got totally

[00:54:19] out of my mind if I did that no I I I've said too many things

[00:54:23] that are incompatible with that

[00:54:27] um on that note I'm aware it's been a bit of a Whistle Stop tour of various topics I want

[00:54:30] to very quickly open up questions to the audience I'm sure

[00:54:34] that'll be a lot I'm afraid we're about to get through everyone uh but

[00:54:38] if I call upon you uh please wait whilst uh

[00:54:42] um my colleague here brings you a microphone stand up and asked me to steal your

[00:54:45] question I call upon the I'll remember in the black

[00:54:49] quarter zip in the front row

[00:54:53] foreign thank you so much for sharing

[00:54:57] your thoughts the question that I have for you is that there are two things that

[00:55:01] I've learned that first is that there's some parts of technology that

[00:55:05] you're excited about some part you aren't which is surprising and second

[00:55:08] is that stagnation is not exciting to anyone so

[00:55:12] in your personal capacity with someone who has the power position and

[00:55:16] money to either solve or influence these problems

[00:55:19] what how are you contributing to it

[00:55:23] so I didn't quite hear the question could you repeat the question yeah the question is

[00:55:27] that in your personal capacity how are you trying to solve

[00:55:30] the problem of stagnation and secondly there are some parts

[00:55:34] of technology that you're not happy about are you going about solving them

[00:55:38] with the Investments that you've made um sure I mean I'm not

[00:55:42] here to flog all my investments but yes that is my day job is

[00:55:45] I'm a venture capitalist and um I uh

[00:55:49] you know I try I try to invest in business that are both successful and

[00:55:53] that somehow create um major positive externalities

[00:55:57] for the world and that uh and and I've yeah I've

[00:56:01] tried doing things in all these different verticals it's quite hard

[00:56:04] outside of I.T outside of computers but I have I've tried

[00:56:08] a wide range of wide range of these things and that's that's

[00:56:12] probably my that's that's the primary thing and then secondarily

[00:56:15] not you know not zero percent I I also try talking about

[00:56:19] it like right now

[00:56:23] um The Honorable member with the blonde hair over here

[00:56:32] hi my name is Alison thank you for being here um I'm in

[00:56:37] terms of your personal sense of spree of sorry free

[00:56:40] speech uh in your writings that you've been doing for decades

[00:56:44] I imagine your ideas evolve do you ever regret anything

[00:56:48] that you've written and if so um does

[00:56:51] that influence the way that you communicate and do you ever regret

[00:56:55] or I'm sorry have fear of future regret

[00:57:01] uh regret sort of an ambiguous word yeah

[00:57:04] there are all sorts of things um there are all sorts of ways that speaking

[00:57:08] is dangerous writing is even more dangerous uh you

[00:57:12] can um you know I remember um back in the 1980s

[00:57:16] was uh sort of one of these sort of conservative people the Hoover institution told

[00:57:19] me that yeah you know it was um writing a book was a more dangerous

[00:57:23] undertaking than having a child because um if the child turned

[00:57:26] out badly you could always disown your child but you could never disown anything that you had

[00:57:30] you had written and that that struck me at the time as this slightly

[00:57:34] ridiculous academic perspective on the world um

[00:57:37] but yes there there's there's something about these things that's that's quite

[00:57:41] you know it's it's um it's it's

[00:57:45] there's something about this that's uncomfortable and uh and I you

[00:57:49] know I I don't know I I draw some balance in between I probably

[00:57:52] say more than I should and uh and uh less

[00:57:56] than I um might have a mind too

[00:58:00] uh you'll remember in the gray sweatshirt the front row here

[00:58:07] thank you um given that the left dominates mainstream

[00:58:11] culture why isn't the right producing more great art

[00:58:14] what means what why

[00:58:18] is it or why is it not why is it not producing more great art yeah the

[00:58:22] right I don't know it's it's uh these things are these

[00:58:26] things are all super hard to do I I

[00:58:30] um I I always I always am encouraging

[00:58:34] people who do things I'm it's it's not the sort of thing I I

[00:58:38] know much about at all like I have some idea of how to how to produce

[00:58:42] um um Innovative tech companies science companies

[00:58:46] um but uh but you know it's it's always there's always a

[00:58:50] part of it um Let me let me do let me do one version on the hall the Hollywood

[00:58:54] movie version where I've been you know I've gotten pulled into you

[00:58:58] know a number of these projects over the years and there's always a somewhat

[00:59:02] stale conservative argument that you know it's it's all very

[00:59:05] biased and um it's you know it's a machine and they

[00:59:09] don't they don't allow anybody with um dissenting views to

[00:59:13] produce um to produce movies that don't fit the um the

[00:59:17] sort of center-left zombie straight jacket or whatever you want to call

[00:59:20] it and all that may be true but but um

[00:59:24] the problem is um you know it's always an and you need to yeah

[00:59:28] you need to do you it needs to still be very high

[00:59:31] quality it's still extremely hard to do this and

[00:59:35] uh and if we when we frame these things too ideologically

[00:59:39] um that often becomes an excuse for for um you

[00:59:43] know um uh losing sight of how hard it is to get the quality

[00:59:47] high enough so uh yeah I I suspect I don't know

[00:59:51] that much about the art world per se I suspect there is it's it's a

[00:59:55] crazed you know left-wing racket I and believe that

[00:59:58] and then um then I think uh most uh most people who

[01:00:02] go to Art School are just are just really lousy at it and that includes most conservatives who

[01:00:06] are in art school um The Honorable and

[01:00:09] perspective called member uh in the third row here uh the

[01:00:13] red red scarf yeah hi thanks uh

[01:00:17] Alp during an MSC in environmental sustainability and Enterprise

[01:00:21] um I want to ask you a question on climate change um and perhaps kindly

[01:00:25] push back on the statement that you made that um the left or the greatest

[01:00:28] of the world do not advocate for technology oriented

[01:00:32] solutions to climate particularly given um the

[01:00:36] Biden administration's recently passing of the impression reduction act

[01:00:39] the single biggest investment in climate uh ever

[01:00:43] which provides in hundreds ofbillions in incentives for hydrogen

[01:00:47] EVS storage wind solar ccos

[01:00:50] all the above so kind of given that what is your

[01:00:54] solution to climate change and how does that align with

[01:00:59] the political donations um that you've made in the US and

[01:01:03] also a mcgregated person and she's she can actually be quite lovely in person

[01:01:08] well well I think um

[01:01:12] again it's a very it's a very multi-dimensional

[01:01:16] thing I um I I tend not to agree with the Marxist analysis

[01:01:20] of measuring input so I don't care whether the government's spending tens of billions or hundreds

[01:01:24] of billions of dollars I'd be interested in measuring output and

[01:01:29] um and probably the um you know the very the very

[01:01:33] difficult challenge with Energy Technologies are you want

[01:01:36] you somehow want things that are cheaper cleaner you

[01:01:40] know that uh that uh that uh that uh

[01:01:44] that somehow uh meet a lot of these criteria and that's

[01:01:48] that's not quite what we're what we're trending towards and

[01:01:51] uh and certainly my my rough calibration of

[01:01:55] the energy around uh people concerned

[01:01:59] with climate change is that it has it's about like 95

[01:02:03] Luddite and about five percent you know accelerationist

[01:02:07] it's it's more keep the thermostat down and wear a sweater

[01:02:11] um and it's it's it's not really we're going to invest in thorium

[01:02:15] to develop a third track of of along

[01:02:19] with uranium and plutonium for nuclear power technology

[01:02:22] so they're you know that I don't hear I hear more excitement about wearing sweaters

[01:02:26] or riding bicycles than uh than uh working on thorium

[01:02:30] plants and uh and um and then and

[01:02:34] then you know and then and then you're not even allowed to of course comment

[01:02:38] uh if you comment on you know how the windmills don't seem to be the most efficient

[01:02:41] thing then I then I end up being like Don Quixote or something like that but uh

[01:02:46] um um probably to have one or two more questions you'll

[01:02:50] remember the heart for college scarf

[01:02:54] thank you uh full disclosure I'm a

[01:02:57] you and your companies have an extensive record investing in healthcare and biotech

[01:03:02] and palantir is as has been widely covered pursuing a

[01:03:05] major NHS data contract which has seen a great deal of

[01:03:09] opposition the NHS being a major State

[01:03:13] operation how would you fix it

[01:03:20] um well that that's uh man that is uh you

[01:03:24] know it's always you these ques all these uh one thing is always tricky about

[01:03:27] all these political questions is there's sort of like a theory and practice so in

[01:03:31] theory um there's all sorts of things one would do very

[01:03:35] differently and you know it's uh in practice like you know what we do if you're

[01:03:38] president United States and it's always the superposition of you know on the one hand you're like the

[01:03:42] dictator on the other hand you're the mayor just kissing babies and Theory

[01:03:46] or dictator and practice your mayor kissing babies and so um and

[01:03:49] so in theory I mean you know you just rip

[01:03:53] the whole thing from the ground Out start over and in practice uh you

[01:03:57] have to somehow uh make it all all backwards compatible and

[01:04:01] and all these uh you know ridiculous British ways in the

[01:04:04] case of the NHS um I uh I

[01:04:08] I suppose I suppose again

[01:04:12] um I suppose the you know the first step the

[01:04:16] thing that seems very odd for an outside Observer

[01:04:19] of Britain is that is a sort of Stockholm syndrome people have with

[01:04:23] respect to the NHS where it's like uh it's like they think it is the most wonderful

[01:04:27] thing in the world and uh and perhaps um you know

[01:04:30] perhaps the you know the um the first step is to just understand

[01:04:34] it as as a as a very iatrogenic institution

[01:04:38] you know sort of play some formula where we can go through you know all the institutions

[01:04:41] in our society and think of them as more iatrogenic than healthy you know the highways

[01:04:45] create traffic jams and Welfare creates poverty and the schools make people dumb

[01:04:49] and the NHS makes people sick and that's that's what I

[01:04:52] would start with I would start by

[01:04:56] well I like use that the first step is you have to get out of the Stockholm

[01:05:00] syndrome that uh that thatit's that it's that it's anywhere close to working

[01:05:03] and then yeah there are there are all kinds of there

[01:05:07] are all kinds of ways you would try to um um you

[01:05:11] I mean you have to go into all the layers but you'd uh try to

[01:05:14] figure out ways to have Market mechanisms um

[01:05:18] uh you try to you try to avoid rationing you try

[01:05:21] to um you try to make it uh uh less regulated

[01:05:25] than it is those would be those would be my those would be my intuitions when

[01:05:29] you say introduce Market mechanisms do you mean privatize feather

[01:05:34] um you would you'd you'd you'd you'd you'd try to find elements

[01:05:37] that you could privatize you would try to you know obviously you

[01:05:41] um you know we live in a society where you can't privatize these things completely so but

[01:05:45] uh but even even the uh even the parts that would be subsidized

[01:05:49] you try to find market mechanisms even for the uh for uh for

[01:05:53] the parts that uh that are treated as a form of welfare the

[01:05:56] CEO of NHS England is the next librarian of the union and is coming back this term so

[01:06:00] I'll be sure to pass on your comments to her um I'm afraid

[01:06:04] I think that's all we have time for this evening ladies and gentlemen um but before

[01:06:07] we thank Mr teal for his time um I'll ask you the

[01:06:11] question we ask all of our speakers at the end of our talk which is if you could give one piece of advice

[01:06:15] to the members of the Oxford Union and the students at the University of Oxford well

[01:06:18] that one piece of advice be well it is

[01:06:22] um it is it is sort of along the lines of what I've already articulated which is always

[01:06:26] that uh um uh you know these sorts

[01:06:29] of debates discussions are um are absolutely important

[01:06:33] they're sacred but they're they're they are also

[01:06:37] just just the first step and we we need a you know a little bit more

[01:06:40] of the sort of um Faust and go to where you know in

[01:06:44] the beginning is the deed and we need we need talk but also action

[01:06:49] ladies and Gentlemen please join me in thanking Mr Peach teal

[01:07:07] [Music]


